{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **Autor:**  Iñigo Pikabea\n\n**Descripción:** El objetivo en este notebook es crear un modelo capaz de responder preguntas sobre covid con un enfoque de extraccion de informacion. Es decir, pasada una pregunta como parametro, el algoritmo buscara entre los documentos del dataset \"CORD-19\", y en base a los documentos con mayor posibilidad de tener la respuesta, se usara el modelo de BERT fine-tuneado para responder a la pregunta con el contexto de dichos documentos seleccionados.","metadata":{}},{"cell_type":"code","source":"!pip install Whoosh","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:00:26.327168Z","iopub.execute_input":"2022-05-11T10:00:26.327493Z","iopub.status.idle":"2022-05-11T10:00:39.390907Z","shell.execute_reply.started":"2022-05-11T10:00:26.327411Z","shell.execute_reply":"2022-05-11T10:00:39.389904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os.path \nimport codecs \nimport pandas as pd \nimport json \nfrom IPython.core.display import display, HTML\nfrom whoosh.index import *\nfrom whoosh.fields import *\nfrom whoosh import qparser\nimport torch \nfrom transformers import BertTokenizer, BertForQuestionAnswering, BasicTokenizer\nfrom transformers.data.metrics.squad_metrics import _get_best_indexes","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:04:30.249399Z","iopub.execute_input":"2022-05-11T10:04:30.250339Z","iopub.status.idle":"2022-05-11T10:04:30.256726Z","shell.execute_reply.started":"2022-05-11T10:04:30.250298Z","shell.execute_reply":"2022-05-11T10:04:30.255963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Retriever","metadata":{}},{"cell_type":"code","source":"# Define path for CORD-19 dataset and its metadata file\npath_dataset = '/kaggle/input/CORD-19-research-challenge/'\npath_mdata = path_dataset + 'metadata.csv'\n\n# Select interesting fields from metadata file\nfields = ['cord_uid','title', 'publish_time', 'abstract', 'journal','url', 'pmcid', 'sha', 'pmc_json_files', 'pdf_json_files']\n\n# Extract selected fields from metadata file into dataframe\ndf_mdata = pd.read_csv(path_mdata, skipinitialspace=True, index_col='cord_uid',usecols=fields)\n\n# WARNING: cord_uid is described as unique, but some of them are repeated. So we keep just the first one\ndf_mdata = df_mdata.loc[~df_mdata.index.duplicated(keep='first')]\n\nprint(\"Number of papers loaded from metadata (after filtering out the repeated ones):\", len(df_mdata))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:04:34.313457Z","iopub.execute_input":"2022-05-11T10:04:34.313759Z","iopub.status.idle":"2022-05-11T10:05:13.331175Z","shell.execute_reply.started":"2022-05-11T10:04:34.313728Z","shell.execute_reply":"2022-05-11T10:05:13.327695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of COVID-19 synonyms\nsynonyms = [\n    'coronavirus 2019',\n    'coronavirus disease 19',\n    'cov2',\n    'cov-2',\n    'covid',\n    'ncov 2019',\n    '2019ncov',\n    '2019-ncov',\n    '2019 ncov',\n    'novel coronavirus',\n    'sarscov2',\n    'sars-cov-2',\n    'sars cov 2',\n    'severe acute respiratory syndrome coronavirus 2',\n    'wuhan coronavirus',\n    'wuhan pneumonia',\n    'wuhan virus'\n]\n\n# Create a filter with 'False' values\nindex_list =  list(df_mdata.index.values) \nfilter = pd.Series([False] * len(index_list))\nfilter.index = index_list\n  \n###IT HAS BEEN REMOVED TO CHECK SYNONYMS IN THE ABSTRACT BECAUSE, \n###AS THEY HAVE UPDATED THE DATAET AND NOW THERE ARE MORE THAN 1 MILLION PAPERS, \n###IT EXCEEDED THE RAM AND COULD NOT CONTINUE WITH THE PROJECT. FOR THIS REASON IT ONLY USES THE SYNONYMS IN THE TITLE.\n\n# Update the filter using the synonym list, checking if a synonym appears in the title or the abstract of a paper\nfor s in synonyms:\n    # Check if a synonym is in title or abstract\n    filter = filter | df_mdata.title.str.lower().str.contains(s) #| df_mdata.abstract.str.lower().str.contains(s)\n\n# Filter out papers in metadata dataframe using the above filter\ndf_mdata = df_mdata[filter]\n\n# Sanity check\nprint(\"After filtering, number of papers in metadata related to 'COVID-19':\", len(df_mdata))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:05:19.42014Z","iopub.execute_input":"2022-05-11T10:05:19.421133Z","iopub.status.idle":"2022-05-11T10:05:48.684844Z","shell.execute_reply.started":"2022-05-11T10:05:19.421077Z","shell.execute_reply":"2022-05-11T10:05:48.683753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_mdata = df_mdata.sample(n = 4000)\nprint(\"After filtering more, number of papers in metadata related to 'COVID-19':\", len(df_mdata))\n\n# Schema definition:\nschema = Schema(id = ID(stored=True,unique=True),\n                path = ID(stored=True),\n                title = TEXT(analyzer=analysis.StemmingAnalyzer()),\n                text = TEXT(analyzer=analysis.StemmingAnalyzer())\n               )\n\n# Create an index\nif not os.path.exists(\"index\"):\n    os.mkdir(\"index\")\n\nix = create_in(\"index\", schema)\n\n# Add papers to the index, iterating through each row in the metadata dataframe\nwriter = ix.writer()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:06:12.49767Z","iopub.execute_input":"2022-05-11T10:06:12.498339Z","iopub.status.idle":"2022-05-11T10:06:12.572756Z","shell.execute_reply.started":"2022-05-11T10:06:12.498288Z","shell.execute_reply":"2022-05-11T10:06:12.57161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_indexed = []\nindexed_sha = []\n\nnum = 0\nfor ind in df_mdata.index: \n    indexed = False\n    if num % 1000 == 0:\n        print(num)\n    num = num+1\n    \n    # If paper has an abstract, index the abstract\n    if not pd.isnull(df_mdata.loc[ind,'abstract']):\n        if pd.isnull(df_mdata.loc[ind,'title']):\n            df_mdata.at[ind,'title'] = \"\"\n        # Add document to the index\n        writer.add_document(id=ind+\"##abs\", title=df_mdata['title'][ind], text=df_mdata['abstract'][ind])\n        indexed = True\n    \n    # If paper has PMC or PDF full text, access its JSON file and index each paragraph separately\n    # First check if paper has PMC xml\n    if not pd.isnull(df_mdata.loc[ind,'pmc_json_files']):\n        if pd.isnull(df_mdata.loc[ind,'title']):\n            df_mdata.at[ind,'title'] = \"\"\n        \n        # Find JSON file: path specified in 'full_text_file', file name specidfied in 'pmcid'\n        path_json = path_dataset + df_mdata['pmc_json_files'][ind]\n        with open(path_json, 'r') as j:\n            jsondata = json.load(j)\n            \n            ## Iterate through paragraphs of body_text\n            for p, paragraph in enumerate(jsondata['body_text']):  \n                # Add document to the index\n                writer.add_document(id=ind+\"##pmc-\" + str(p), path = path_json, title=df_mdata['title'][ind], text=paragraph['text'])\n                indexed = True\n    \n    # As current paper does not have PMC, check if it has JSON PDF\n    elif not pd.isnull(df_mdata.loc[ind,'pdf_json_files']):\n        if pd.isnull(df_mdata.loc[ind,'title']):\n            df_mdata.at[ind,'title'] = \"\"\n        \n        # Find JSON file: path specified in 'full_text_file', file name specidfied in 'sha'\n        # There could be more than one reference in 'sha' separated by ;\n        shas = df_mdata['pdf_json_files'][ind].split(';')\n        for sha in shas:\n            sha = sha.strip()\n            # Check if paper with this sha has been indexed already\n            if sha not in indexed_sha:\n                indexed_sha.append(sha)\n                path_json = path_dataset + sha\n                with open(path_json, 'r') as j:\n                    jsondata = json.load(j)\n            \n                    ## iterate through paragraphs of body_text\n                    for p, paragraph in enumerate(jsondata['body_text']):  \n                        # Add document to the index\n                        writer.add_document(id=ind+\"##pdf-\" + str(p), path = path_json, title=df_mdata['title'][ind], text=paragraph['text'])\n                        indexed = True\n    \n    if not indexed:\n        not_indexed.append(ind)\n        \n# Save the added documents\nwriter.commit()\nprint(\"Index successfully created\")\n\n# Sanity check\nprint(\"Number of documents (abstracts and paragraphs of papers) in the index: \", ix.doc_count())\nprint(\"Number of papers not indexed (because they don't have neither the abstract nor full text): \", len(not_indexed))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:06:30.137736Z","iopub.execute_input":"2022-05-11T10:06:30.138523Z","iopub.status.idle":"2022-05-11T10:07:54.587898Z","shell.execute_reply.started":"2022-05-11T10:06:30.138477Z","shell.execute_reply":"2022-05-11T10:07:54.586948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input: Question, dataframe that contains metadata info, maximum number of documents to retrieve\ndef retrieve_docs(qstring, df_metadata, n_docs):\n\n    # Open the searcher for reading the index. The default BM25F algorithm will be used for scoring\n    with ix.searcher() as searcher:\n        searcher = ix.searcher()\n        \n        # Define the query parser ('text' will be the default field to search), and set the input query\n        q = qparser.QueryParser(\"text\", ix.schema, group=qparser.OrGroup).parse(qstring)\n    \n        # Search using the query q, and get the n_docs documents, sorted with the highest-scoring documents first\n        results = searcher.search(q, limit=n_docs)\n        # results is a list of dictionaries where each dictionary is the stored fields of the document (id, path). 'title' and text' are not stored\n    \n    # Create columns (id, date, journal, title, text and score) for a new dataframe which will be used to store the results\n    ids = []\n    dates = []\n    journals = []\n    titles = []\n    texts = []\n    scores = [] \n    # Iterate over the retrieved documents to fill in the new dataframe\n    for hit in results:\n        # Add id to the new dataframe\n        ids.append(hit['id'])\n        \n        # As year, title and text are not stored in the index, they are not returned in results object. They have to be extracted from metadata\n        # Get paper id and type of section (abstract, full text paragraph from pmc or pdf)\n        pid,sect = hit['id'].split(\"##\") # id examples: 'vho70jcx##pmc-1', a5x5ga60##abs\n        \n        # Add year to the new dataframe\n        if pd.isnull(df_metadata.loc[pid,'publish_time']):\n            dates.append(\"\")\n        else:\n            dates.append(df_metadata['publish_time'][pid])\n            \n        # Add journal to the new dataframe\n        if pd.isnull(df_metadata.loc[pid,'journal']):\n            journals.append(\"unknown journal\")\n        else:\n            journals.append(df_metadata['journal'][pid])\n        \n        # Add title (with link to the doi, if exists) to the new dataframe \n        if pd.isnull(df_metadata.loc[pid,'url']):\n            titles.append(df_metadata['title'][pid])\n        else:\n            titles.append(\"<a target=blank href=\\\"\" + df_metadata['url'][pid] + \"\\\">\" + df_metadata['title'][pid] + \"</a>\")\n        \n        # Add text to the new dataframe\n        if sect == 'abs': # get text of the abstract (reading from metadata)\n            texts.append(df_metadata['abstract'][pid])\n        else: # get text of the paragraph (reading from a JSON file)\n            # get pmc or pdf, and the number of paragraph in body full text\n            json_type,nsect = sect.split(\"-\") # sect examples: 'pmc-1', 'pdf-5'\n    \n            # path of the JSON file whether text has been extracted from PMC or PDF\n            #if json_type == 'pmc':\n            #    path_json = path_dataset + df_metadata['full_text_file'][pid] + '/' + df_metadata['full_text_file'][pid] + '/pmc_json/' + df_metadata['pmcid'][pid] + '.xml.json'    \n            #else: \n            #    path_json = path_dataset + df_metadata['full_text_file'][pid] + '/' + df_metadata['full_text_file'][pid] + '/pdf_json/' + df_metadata['sha'][pid] + '.json'\n            with open(hit['path'], 'r') as j:\n                jsondata = json.load(j)\n                texts.append(jsondata['body_text'][int(nsect)]['text'])\n        \n        # Add score to the new dataframe\n        scores.append(hit.score)\n    \n    # Create a dataframe of results with the columns\n    df_results = pd.DataFrame()\n    df_results['id'] = ids\n    df_results['date'] = dates\n    df_results['journal'] = journals\n    df_results['title'] = titles\n    df_results['text'] = texts\n    df_results['score'] = scores\n    \n    \n    return df_results\n    # Output: Dataframe where each line is a relevant paragraph, and the columns are the following:\n    #         id, date, journal, title, text, score","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:09:27.466023Z","iopub.execute_input":"2022-05-11T10:09:27.466514Z","iopub.status.idle":"2022-05-11T10:09:27.483635Z","shell.execute_reply.started":"2022-05-11T10:09:27.466464Z","shell.execute_reply":"2022-05-11T10:09:27.482899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reader","metadata":{}},{"cell_type":"code","source":"def extract_answers(qstring, df_results, n_answers, max_answer_len):\n    \n    # Set tokenizer to lower case the paragraph\n    basic_tokenizer = BasicTokenizer(do_lower_case=False)\n    \n    answers = []\n    # Iterate over the paragraphs\n    for i, context in enumerate(df_results['text']):\n        context = ' '.join(basic_tokenizer.tokenize(context))\n        # Add for QuAC\n        context += ' CANNOTANSWER'\n        # Call a function to extract answers from a paragraph (context)\n        answers.append(run_qa(qstring, context, n_answers, max_answer_len))  \n        # Remove it from context\n        context = context.replace(' CANNOTANSWER', '')\n        df_results['text'][i] = context\n    # Add answer to the results dataframe\n    df_results['qa_answers'] = answers\n    \n    return df_results","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:09:33.424556Z","iopub.execute_input":"2022-05-11T10:09:33.424859Z","iopub.status.idle":"2022-05-11T10:09:33.432373Z","shell.execute_reply.started":"2022-05-11T10:09:33.42483Z","shell.execute_reply":"2022-05-11T10:09:33.431648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('/kaggle/input/bertforqasquad/')\nbasic_tokenizer = BasicTokenizer(do_lower_case=False)\nmodel = BertForQuestionAnswering.from_pretrained('/kaggle/input/bertforqasquad/')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:10:57.505414Z","iopub.execute_input":"2022-05-11T10:10:57.506241Z","iopub.status.idle":"2022-05-11T10:11:03.74018Z","shell.execute_reply.started":"2022-05-11T10:10:57.506205Z","shell.execute_reply":"2022-05-11T10:11:03.739171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_qa(question, context, nbest, max_answer_len):\n    \n    tokenizer_dict = tokenizer.encode_plus(text=question, text_pair=context, max_length=384, stride=120,\n                                           return_overflowing_tokens=True, truncation='only_second')   \n    input_ids = [tokenizer_dict['input_ids']]\n    input_type_ids = [tokenizer_dict['token_type_ids']]  \n        \n    outputs = model(torch.tensor(input_ids), token_type_ids = torch.tensor(input_type_ids)) \n    answers = []\n    \n    for i in range(len(input_ids)):\n        start_logits = outputs['start_logits'].detach().cpu().tolist()[0]\n        end_logits = outputs['end_logits'].detach().cpu().tolist()[0]\n        answers += compute_predictions(start_logits, end_logits, input_ids[i], context.lower(), nbest, max_answer_len)\n    \n    answers.sort(key = lambda x: x['score'], reverse=True)\n    return answers[0:nbest]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:11:10.730348Z","iopub.execute_input":"2022-05-11T10:11:10.731303Z","iopub.status.idle":"2022-05-11T10:11:10.742969Z","shell.execute_reply.started":"2022-05-11T10:11:10.731256Z","shell.execute_reply":"2022-05-11T10:11:10.741746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_predictions(start_logits, end_logits, input_ids, context, nbest, max_answer_length):\n    start_indexes = _get_best_indexes(start_logits, nbest + 10)\n    end_indexes = _get_best_indexes(end_logits, nbest + 10)\n    answers = []\n    for start_index in start_indexes:\n        for end_index in end_indexes:\n            #Avoid invalid predictions\n            answer_len = end_index - start_index + 1\n            if end_index < start_index:\n                continue\n            if max_answer_length < answer_len:\n                continue\n            text = tokenizer.decode(input_ids[start_index:start_index + answer_len], clean_up_tokenization_spaces=False)\n            try:\n                original_start_index = context.index(text)\n                original_end_index = original_start_index + len(text)\n            except:\n                #If there is any problem when looking for the answer in the text\n                #For example:\n                # System says answer in is question\n                # Or special tokens in answer [SEP] [PAD]\n                continue   \n            #When answer contains text and cannotanswer remove the cannotanswer part \n            if text != 'cannotanswer':\n                text.replace(' cannotanswer', '')\n            answer = {'text': text.capitalize(),\n                     'score': start_logits[start_index] + end_logits[end_index],\n                     'start_index': original_start_index,\n                     'end_index': original_end_index}\n            answers.append(answer)  \n    return answers","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:11:14.176691Z","iopub.execute_input":"2022-05-11T10:11:14.176996Z","iopub.status.idle":"2022-05-11T10:11:14.189549Z","shell.execute_reply.started":"2022-05-11T10:11:14.176966Z","shell.execute_reply":"2022-05-11T10:11:14.188626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tasks = [\n    {\n        'task': \"Task1 - What is known about transmission, incubation, and environmental stability?\",\n        'questions': [\n            \"Range of incubation periods for the disease in humans\",\n            \"Range of incubation periods for the disease in humans depending on age\",\n            \"Range of incubation periods for the disease in humans depending on health status\",\n            \"How long individuals are contagious?\",\n            \"Prevalence of asymptomatic shedding and transmission\",\n            \"Prevalence of asymptomatic shedding and transmission in children\",\n            \"Seasonality of transmission\",\n            \"Charge distribution\",\n            \"Adhesion to hydrophilic/phobic surfaces\",\n            \"Environmental survival to inform decontamination efforts for affected areas\",\n            \"Viral shedding\",\n            \"Persistence and stability on nasal discharge\",\n            \"Persistence and stability on sputum\",\n            \"Persistence and stability on urine\",\n            \"Persistence and stability on fecal matter\",\n            \"Persistence and stability on blood\",\n            \"Persistence of virus on surfaces of different materials\",\n            \"Persistence of virus on copper\",\n            \"Persistence of virus on stainless steel\",\n            \"Persistence of virus on plastic\",\n            \"Natural history of the virus\",\n            \"Shedding the virus from an infected person\",\n            \"Implementation of diagnostics to improve clinical processes\",\n            \"Implementation of products to improve clinical processes\",\n            \"Disease models, including animal models for infection, disease and transmission\",\n            \"Tools to monitor phenotypic change and potential adaptation of the virus\",\n            \"Studies to monitor phenotypic change and potential adaptation of the virus\",\n            \"Immune response and immunity\",\n            \"Effectiveness of movement control strategies to prevent secondary transmission in health care and community settings\",\n            \"Effectiveness of personal protective equipment (PPE) and its usefulness to reduce risk of transmission in health care and community settings\",\n            \"Role of the environment in transmission\"\n         ]\n    },\n    {\n        'task': \"Task 2 - What do we know about COVID-19 risk factors?\",\n        'questions': [\n            \"Which are the main risk factors?\",\n            \"Does smoking increase risk for COVID-19?\",\n            \"Is a pre-existing pulmonary disease a risk factor for COVID-19?\",\n            \"Do co-infections increase risk for COVID-19?\",\n            \"Does a respiratory or viral infection increase risk for COVID-19?\",\n            \"Are neonates at increased risk of COVID-19?\",\n            \"Are pregnant women at increased risk of COVID-19?\",\n            \"Is there any socio-economic factor associated with increased risk for COVID-19?\",\n            \"Is there any behavioral factor associated with increased risk for COVID-19?\",\n            \"What is the basic reproductive number?\",\n            \"What is the incubation period?\",\n            \"What are the modes of transmission?\",\n            \"What are the environmental factors?\",\n            \"Risk of fatality among symptomatic hospitalized patients\",\n            \"Risk of fatality among high-risk patient groups\",\n            \"Susceptibility of populations\",\n            \"Public health mitigation measures that could be effective for control\"\n        ]\n    },\n    {\n        'task': \"Task 3 - What do we know about virus genetics, origin, and evolution?\",\n        'questions': [\n            \"Real-time tracking of whole genomes to inform the development of diagnostics\",\n            \"Real-time tracking of whole genomes to inform the development of therapeutics\",\n            \"Real-time tracking of whole genomes to track variations of the virus over time\",\n            \"Mechanism for coordinating the rapid dissemination of whole genomes to inform the development of diagnostics\",\n            \"Mechanism for coordinating the rapid dissemination of whole genomes to inform the development of therapeutics\",\n            \"Mechanism for coordinating the rapid dissemination of whole genomes to track variations of the virus over time\",\n            \"Which geographic and temporal diverse sample sets are accessed to understand geographic differences?\",\n            \"Which geographic and temporal diverse sample sets are accessed to understand genomic differences?\",\n            \"Is there more than one strain in circulation?\",\n            \"Is any multi-lateral agreement leveraged such as the Nagoya Protocol?\",\n            \"Is there evidence that livestock could be infected and serve as a reservoir after the epidemic appears to be over?\",\n            \"Has there been any field surveillance to show that livestock could be infected?\",\n            \"Has there been any genetic sequencing to show that livestock could be infected?\",\n            \"Has there been any receptor binding to show that livestock could be infected?\",\n            \"Is there evidence that farmers are infected?\",\n            \"Is there evidence that farmers could have played a role in the origin?\",\n            \"What are the results of the surveillance of mixed wildlife-livestock farms for SARS-CoV-2 and other coronaviruses in Southeast Asia?\",\n            \"What are the results of the experimental infections to test host range for this pathogen?\",\n            \"Which are the animal hosts?\",\n            \"Is there evidence of continued spill-over to humans from animals?\",\n            \"Which are the socioeconomic and behavioral risk factors for the spill-over to humans from animals?\",\n            \"Sustainable risk reduction strategies\"\n        ]\n    },\n    {\n        'task': \"Task 4 - What do we know about vaccines and therapeutics?\",\n        'questions': [\n            \"What is known about the effectiveness of drugs being developed to treat COVID-19 patients?\",\n            \"What is known about the effectiveness of drugs tried to treat COVID-19 patients?\",\n            \"Show results of clinical and bench trials to investigate less common viral inhibitors against COVID-19\",\n            \"Show results of clinical and bench trials to investigate naproxen against COVID-19\",\n            \"Show results of clinical and bench trials to investigate clarithromycin against COVID-19\",\n            \"Show results of clinical and bench trials to investigate Minocyclinethat against COVID-19\",\n            \"Which are the methods evaluating potential complication of Antibody-Dependent Enhancement (ADE) in vaccine recipients?\",\n            \"What is known about the use of best animal models and their predictive value for a human vaccine?\",\n            \"Capabilities to discover a therapeutic for the disease\",\n            \"Clinical effectiveness studies to discover therapeutics, to include antiviral agents\",\n            \"Which are the models to aid decision makers in determining how to prioritize and distribute scarce, newly proven therapeutics?\",\n            \"Efforts targeted at a universal coronavirus vaccine\",\n            \"Efforts to develop animal models and standardize challenge studies\",\n            \"Efforts to develop prophylaxis clinical studies and prioritize in healthcare workers\",\n            \"Approaches to evaluate risk for enhanced disease after vaccination\",\n            \"Assays to evaluate vaccine immune response\",\n            \"Process development for vaccines, alongside suitable animal models\"\n        ]\n    },\n    {\n        'task': \"Task 5 - What has been published about medical care?\",\n        'questions': [\n            \"Resources to support skilled nursing facilities\",\n            \"Resources to support long term care facilities\",\n            \"Mobilization of surge medical staff to address shortages in overwhelmed communities\",\n            \"Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS)\",\n            \"Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS) for viral etiologies\",\n            \"What are the outcomes of Extracorporeal membrane oxygenation (ECMO) of COVID-19 patients?\",\n            \"What are the outcomes for COVID-19 after mechanical ventilation adjusted for age?\",\n            \"What is known of the frequency, manifestations, and course of extrapulmonary manifestations of COVID-19?\",\n            \"What is known of the frequency, manifestations, and course of cardiomyopathy?\",\n            \"What is known of the frequency, manifestations, and course of cardiac arrest?\",\n            \"Application of regulatory standards (e.g., EUA, CLIA)\",\n            \"Ability to adapt care to crisis standards of care level\",\n            \"Approaches for encouraging and facilitating the production of elastomeric respirators, which can save thousands of N95 masks\",\n            \"Which are the best telemedicine practices?\",\n            \"Which are the facilitators to expand the telemedicine practices?\",\n            \"Which are the specific actions to expand the telemedicine practices?\",\n            \"Guidance on the simple things people can do at home to take care of sick people and manage disease\",\n            \"Which are the oral medications that might potentially work?\",\n            \"Use of artificial intelligence in real-time health care delivery to evaluate interventions\",\n            \"Use of artificial intelligence in real-time health care delivery to evaluate risk factors\",\n            \"Use of artificial intelligence in real-time health care delivery to evaluate outcomes\",\n            \"Which are the challenges, solutions and technologies in hospital flow and organization?\",\n            \"Which are the challenges, solutions and technologies in workforce protection?\",\n            \"Which are the challenges, solutions and technologies in workforce allocation?\",\n            \"Which are the challenges, solutions and technologies in community-based support resources?\",\n            \"Which are the challenges, solutions and technologies in payment?\",\n            \"Which are the challenges, solutions and technologies in supply chain management to enhance capacity, efficiency, and outcomes?\",\n            \"Efforts to define the natural history of disease to inform clinical care, public health interventions, infection prevention control, transmission, and clinical trials\",\n            \"What has been done to develop a core clinical outcome set to maximize usability of data across a range of trials?\",\n            \"Can adjunctive or supportive intervention (e.g. steroids, high flow oxygen)  improve the clinical outcomes of infected patients?\"\n        ]\n    },\n    {\n        'task': \"Task 6 - What do we know about non-pharmaceutical interventions?\",\n        'questions': [\n            \"Which is the best way to scale up NPIs in a more coordinated way to give us time to enhance our health care delivery system capacity to respond to an increase in cases?\",\n            \"Which is the best way to mobilize resources to geographic areas where critical shortfalls are identified?\",\n            \"Rapid design and execution of experiments to examine and compare NPIs currently being implemented\",\n            \"What is known about the efficacy of school closures?\",\n            \"What is known about the efficacy of travel bans?\",\n            \"What is known about the efficacy of bans on mass gatherings?\",\n            \"What is known about the efficacy of social distancing approaches?\",\n            \"Which are the methods to control the spread in communities?\",\n            \"Models of potential interventions to predict costs and benefits depending on race\",\n            \"Models of potential interventions to predict costs and benefits depending on income\",\n            \"Models of potential interventions to predict costs and benefits depending on disability\",\n            \"Models of potential interventions to predict costs and benefits depending on age\",\n            \"Models of potential interventions to predict costs and benefits depending on geographic location\",\n            \"Models of potential interventions to predict costs and benefits depending on immigration status\",\n            \"Models of potential interventions to predict costs and benefits depending on housing status\",\n            \"Models of potential interventions to predict costs and benefits depending on employment status\",\n            \"Models of potential interventions to predict costs and benefits depending on health insurance status\",\n            \"Policy changes necessary to enable the compliance of individuals with limited resources and the underserved with NPIs\",\n            \"Why do people fail to comply with public health advice?\",\n            \"Which is the economic impact of any pandemic?\",\n            \"How can we mitigate risks to critical government services in a pandemic?\",\n            \"Alternatives for food distribution and supplies in a pandemic\",\n            \"Alternatives for household supplies in a pandemic\",\n            \"Alternatives for health diagnoses, treatment, and needed care in a pandemic\"\n        ]\n    },\n    {\n        'task': \"Task 7 - Help us understand how geography affects virality\",\n        'questions': [\n            \"Are there geographic variations in the rate of COVID-19 spread?\",\n            \"Are there geographic variations in the mortality rate of COVID-19?\",\n            \"Is there any evidence to suggest geographic based virus mutations?\"\n        ]\n    },\n    {\n        'task': \"Task 8 - What do we know about diagnostics and surveillance?\",\n        'questions': [\n            \"Which are the sampling methods to determine asymptomatic disease?\",\n            \"What can we do for early detection of disease?\",\n            \"Is the use of screening of neutralizing antibodies such as ELISAs valid for early detection of disease?\",\n            \"Which are the existing diagnostic platforms?\",\n            \"Which are the existing surveillance platforms?\",\n            \"Recruitment, support, and coordination of local expertise and capacity\",\n            \"How states might leverage universities and private laboratories for testing purposes?\",\n            \"Which are the best ways for communications to public health officials and the public?\",\n            \"What is the speed, accessibility, and accuracy of a point-of-care test?\",\n            \"What is the speed, accessibility, and accuracy of rapid bed-side tests?\",\n            \"Rapid design and execution of targeted surveillance experiments calling for all potential testers using PCR in a defined area to start testing and report to a specific entity\",\n            \"Separation of assay development issues from instruments\",\n            \"Which is the role of the private sector to help quickly migrate assays?\",\n            \"What has been done to track the evolution of the virus?\",\n            \"Latency issues and when there is sufficient viral load to detect the pathogen\",\n            \"What is needed in terms of biological and environmental sampling?\",\n            \"Use of diagnostics such as host response markers (e.g., cytokines) to detect early disease or predict severe disease progression\",\n            \"Policies and protocols for screening and testing\",\n            \"Policies to mitigate the effects on supplies associated with mass testing, including swabs and reagents\",\n            \"Technology roadmap for diagnostics\",\n            \"Which are the barriers to developing and scaling up new diagnostic tests?\",\n            \"How future coalition and accelerator models could provide critical funding for diagnostics?\",\n            \"How future coalition and accelerator models could provide critical funding for opportunities for a streamlined regulatory environment?\",\n            \"New platforms and technology (CRISPR) to improve response times\",\n            \"New platforms and technology to employ more holistic approaches\",\n            \"Coupling genomics and diagnostic testing on a large scale\",\n            \"What is needed for rapid sequencing and bioinformatics to target regions of the genome that will allow specificity for a particular variant?\",\n            \"What is needed for sequencing with advanced analytics for unknown pathogens?\",\n            \"What is needed for distinguishing naturally-occurring pathogens from intentional?\",\n            \"What is known about One Health surveillance of humans and potential sources of future spillover or ongoing exposure for this organism and future pathogens?\"\n        ]\n    },\n    {\n        'task': \"Task 9 - What has been published about ethical and social science considerations?\",\n        'questions': [\n            \"Articulate and translate existing ethical principles and standards to salient issues in COVID-2019\",\n            \"Embed ethics across all thematic areas, engage with novel ethical issues that arise and coordinate to minimize duplication of oversight\",\n            \"Support sustained education, access, and capacity building in the area of ethics\",\n            \"Establish a team at WHO that will be integrated within multidisciplinary research and operational platforms and that will connect with existing and expanded global networks of social sciences\",\n            \"Develop qualitative assessment frameworks to systematically collect information related to local barriers and enablers for the uptake and adherence to public health measures for prevention and control\",\n            \"How the burden of responding to the outbreak and implementing public health measures affects the physical and psychological health of those providing care for Covid-19 patients?\",\n            \"Identify the underlying drivers of fear, anxiety and stigma that fuel misinformation and rumor, particularly through social media\"\n        ]\n    },\n    {\n        'task': \"Task 10 - What has been published about information sharing and inter-sectoral collaboration?\",\n        'questions': [\n            \"Which are the methods for coordinating data-gathering with standardized nomenclature?\",\n            \"Sharing response information among planners, providers, and others\",\n            \"Understanding and mitigating barriers to information-sharing\",\n            \"How to recruit, support, and coordinate local expertise and capacity relevant to public health emergency response?\",\n            \"Integration of federal/state/local public health surveillance systems\",\n            \"Value of investments in baseline public health response infrastructure preparedness\",\n            \"Modes of communicating with target high-risk populations (elderly, health care workers)\",\n            \"Risk communication and guidelines that are easy to understand and follow\",\n            \"Communication that indicates potential risk of disease to all population groups\",\n            \"Misunderstanding around containment and mitigation\",\n            \"Action plan to mitigate gaps and problems of inequity in the Nation’s public health capability, capacity, and funding to ensure all citizens in need are supported and can access information, surveillance, and treatment\",\n            \"Measures to reach marginalized and disadvantaged populations\",\n            \"Data systems and research priorities and agendas incorporate attention to the needs and circumstances of disadvantaged populations and underrepresented minorities\",\n            \"Mitigating threats to incarcerated people from COVID-19, assuring access to information, prevention, diagnosis, and treatment\",\n            \"Understanding coverage policies (barriers and opportunities) related to testing, treatment, and care\"\n        ]\n    }\n]","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-11T10:35:43.02113Z","iopub.execute_input":"2022-05-11T10:35:43.021479Z","iopub.status.idle":"2022-05-11T10:35:43.055297Z","shell.execute_reply.started":"2022-05-11T10:35:43.021425Z","shell.execute_reply":"2022-05-11T10:35:43.054096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Main","metadata":{}},{"cell_type":"code","source":"# Creates the HTML code to show all the answers colored gradually in the paragraph\ndef color_snippet(text,marks):\n    # Set colors for answers\n    colors = ['#ffebcc', '#ffc266','#ff9900']\n    \n    # Create HTML code to show the colored paragraph\n    html = '<blockquote>'\n    current_mark = 0\n    for i,mark in enumerate(marks):\n        if current_mark != mark:\n            if current_mark != 0:\n                html += '</span>'\n            if mark > 0:\n                html += '<span style=\"background-color: {}\">'.format(colors[mark-1])\n            current_mark = mark\n        html += text[i]\n    if current_mark != 0:\n        html += '</span>'\n    html += '</blockquote>' \n    return html\n\n\n# Set number of this task\nntask = 1\n\n# Show title of the task\ntask_title = tasks[ntask-1]['task']\nhtml = html = \"<p><h1>\" + task_title + \"</h1></p><br>\"\n\n# Set input parameters of the functions above\n# Maximum number of documents to retrieve\nmax_n_docs = 20\n# Maximum number of answers to extract\nmax_n_answers = 3\n# Maximum answer length\nmax_answer_length = 30\n# Amount of Cannotanswers to declare answers as not suitable\nthreshold = 17\n\n# Iterate over all the questions in a task and call the functions above\nitera = 0\nfor nq,question in enumerate(tasks[ntask-1]['questions']):\n    nulled = False\n    itera = itera+1\n    print('Question n.', itera)\n    # Call the function to retrieve relevant paragraphs of papers\n    df_ir_results = retrieve_docs(question, df_mdata, max_n_docs)\n    # Call the function to extract answers from paragraphs\n    df_qa_results = extract_answers(question, df_ir_results, max_n_answers, max_answer_length)\n\n    # Show the question\n    html += '<br><p><font color=\"#683E00\"><h2>{}</h2></font>'.format(question)\n    \n    # Count how many non-null answers are extracted for a question\n    n_cannotanswer = 0\n    for ind in df_qa_results.index:\n        if(df_qa_results['qa_answers'][ind] != []):\n            answer = df_qa_results['qa_answers'][ind][0] \n            #Take SQuAD and QuAC cases into account\n            if answer['text'] == 'Cannotanswer' or len(answer['text'])==0:\n                n_cannotanswer += 1\n        else:\n            nulled = True\n            \n    if n_cannotanswer < threshold and not nulled:\n        # Set maximum number of results to show\n        max_n_results = 5\n        n_results = 0\n        for ind in df_qa_results.index:\n            if n_results == max_n_results:\n                break\n            answers = df_qa_results['qa_answers'][ind]\n            # If the first answer is non-null, show the answer\n            #if answers[0]['text'] != 'CANNOTANSWER':\n            \n            if answers[0]['text'] != 'Cannotanswer' and len(answers[0]['text']) != 0:\n                answer_string = answers[0]['text']\n                answer_string = answer_string.replace('cannotanswer','')\n                html += '<br><b>{}</b> <span style=\"background-color: #dddddd\"> [{}, <i>{}</i>, {}]</span><br>'.format(answer_string, df_qa_results['title'][ind], df_qa_results['journal'][ind], df_qa_results['date'][ind])\n            \n                # Color the paragraph to highlight the answers\n                marks = [0] * len(df_qa_results['text'][ind])\n               \n                for n_ans, answer in enumerate(answers):\n                    if answer['text'] != 'Cannotanswer':\n                        level = max_n_answers - n_ans\n                        start = answer['start_index']\n                        if answer['end_index'] >= len(marks):\n                            end = len(marks)-1\n                        else:\n                            end = answer['end_index']\n                       \n                        for i in range(start,end):\n                            if marks[i] < level:\n                                marks[i] = level\n                html += color_snippet(df_qa_results['text'][ind], marks)\n                n_results += 1        \n        html += '<hr>'\n    else:\n        html += '<br><i>No suitable answers found.</i><br>'\n        html += '<hr>'\n    \n\n# Display the HTML string that contains all the answers\ndisplay(HTML(html))\n\n# Save the HTML code of the answers into a file\nif not os.path.exists(\"html\"):\n    os.mkdir(\"html\")\nhtml_file = codecs.open(\"/kaggle/working/html/task\" + str(ntask) + \".html\",\"w\",\"utf-8\")\nhtml_file.write(html)\nhtml_file.close()","metadata":{},"execution_count":null,"outputs":[]}]}